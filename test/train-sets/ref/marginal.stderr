final_regressor = marginal_model
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
decay_learning_rate = 1
creating cache_file = train-sets/marginal_features.cache
Reading datafile = train-sets/marginal_features
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
0.250000 0.250000            1            1.0   0.5000   0.0000        2
0.358917 0.467835            2            2.0   1.0000   0.3160        2
0.188654 0.018391            4            4.0   1.0000   0.8511        2
0.104133 0.019613            8            8.0   1.0000   0.8699        2
0.052844 0.001554           16           16.0   1.0000   0.9720        2
0.026573 0.000303           32           32.0   1.0000   0.9886        2
0.013325 0.000076           64           64.0   1.0000   0.9946        2
0.006672 0.000019          128          128.0   1.0000   0.9973        2

finished run
number of examples per pass = 2
passes used = 100
weighted example sum = 200.000000
weighted label sum = 150.000000
average loss = 0.004272
best constant = 0.750000
best constant's loss = 0.062500
total feature number = 400
